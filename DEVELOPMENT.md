# Omnipair Indexer Development Guide

This guide provides comprehensive information for developers working on the Omnipair indexer's hybrid Rust/TypeScript architecture.

## ğŸ—ï¸ Architecture Overview

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Web Apps      â”‚  â”‚   Mobile Apps   â”‚  â”‚   Analytics     â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚   Dashboards    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Layer                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           TypeScript API Server (Bun)                      â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚   Routes    â”‚ â”‚  Services   â”‚ â”‚     Middleware      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚             â”‚ â”‚             â”‚ â”‚                     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Health    â”‚ â”‚ â€¢ Pairs     â”‚ â”‚ â€¢ Authentication    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Pairs     â”‚ â”‚ â€¢ Positions â”‚ â”‚ â€¢ Rate Limiting     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Users     â”‚ â”‚ â€¢ Analytics â”‚ â”‚ â€¢ CORS              â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Analytics â”‚ â”‚ â€¢ Prices    â”‚ â”‚ â€¢ Validation        â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ SQL Queries (Drizzle ORM)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Database Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              PostgreSQL + TimescaleDB                      â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚    Core     â”‚ â”‚ Time-Series â”‚ â”‚    Aggregates       â”‚   â”‚ â”‚
â”‚  â”‚  â”‚   Tables    â”‚ â”‚ Hypertables â”‚ â”‚   & Analytics       â”‚   â”‚ â”‚
â”‚  â”‚  â”‚             â”‚ â”‚             â”‚ â”‚                     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Pairs     â”‚ â”‚ â€¢ Txns      â”‚ â”‚ â€¢ Price Feeds       â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Positions â”‚ â”‚ â€¢ Events    â”‚ â”‚ â€¢ Volume Stats      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Config    â”‚ â”‚ â€¢ Logs      â”‚ â”‚ â€¢ User Metrics      â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ Database Writes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Indexing Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Rust Indexer Daemon (Carbon)                  â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Datasources â”‚ â”‚  Processors â”‚ â”‚      Decoders       â”‚   â”‚ â”‚
â”‚  â”‚  â”‚             â”‚ â”‚             â”‚ â”‚                     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ RPC Poll  â”‚ â”‚ â€¢ Accounts  â”‚ â”‚ â€¢ Omnipair Proto    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ WebSocket â”‚ â”‚ â€¢ Events    â”‚ â”‚ â€¢ Instructions      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Backfill  â”‚ â”‚ â€¢ Metrics   â”‚ â”‚ â€¢ Account Types     â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ RPC/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Solana Network                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   RPC Nodes     â”‚  â”‚   WebSocket     â”‚  â”‚   Omnipair      â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚   Endpoints     â”‚  â”‚   Program       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
omnipair-indexer/
â”œâ”€â”€ Cargo.toml                    # Rust workspace configuration
â”œâ”€â”€ package.json                  # Node.js workspace configuration
â”œâ”€â”€ README.md                     # Main project documentation
â”œâ”€â”€ QUICKSTART.md                 # Quick setup guide
â”œâ”€â”€ DEVELOPMENT.md                # This file
â”‚
â”œâ”€â”€ indexer/                      # ğŸ¦€ Rust Indexer Daemon
â”‚   â”œâ”€â”€ Cargo.toml               # Package configuration
â”‚   â”œâ”€â”€ railway.toml             # Railway deployment config
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main.rs              # Main daemon application
â”‚   â”œâ”€â”€ crates/                  # Carbon framework crates
â”‚   â”‚   â”œâ”€â”€ core/                # Core pipeline functionality
â”‚   â”‚   â”œâ”€â”€ macros/              # Helper macros
â”‚   â”‚   â”œâ”€â”€ proc-macros/         # Procedural macros
â”‚   â”‚   â””â”€â”€ test-utils/          # Testing utilities
â”‚   â”œâ”€â”€ datasources/             # Data source implementations
â”‚   â”‚   â””â”€â”€ rpc-program-subscribe-datasource/
â”‚   â”œâ”€â”€ decoders/                # Protocol decoders
â”‚   â”‚   â””â”€â”€ omnipair_decoder/    # Omnipair-specific decoder
â”‚   â”œâ”€â”€ metrics/                 # Metrics implementations
â”‚   â”‚   â”œâ”€â”€ log-metrics/         # Structured logging
â”‚   â”‚   â””â”€â”€ prometheus-metrics/  # Prometheus integration (planned)
â”‚   â””â”€â”€ README.md                # Indexer documentation
â”‚
â”œâ”€â”€ api/                         # ğŸ“¡ TypeScript API Server
â”‚   â”œâ”€â”€ package.json             # API dependencies
â”‚   â”œâ”€â”€ railway.toml             # Railway deployment config
â”‚   â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â”‚   â”œâ”€â”€ src/                     # Source code
â”‚   â”‚   â”œâ”€â”€ index.ts             # Main server entry point
â”‚   â”‚   â”œâ”€â”€ routes/              # API route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ health.ts        # Health endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ pairs.ts         # Pair endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ positions.ts     # Position endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ transactions.ts  # Transaction endpoints
â”‚   â”‚   â”‚   â””â”€â”€ analytics.ts     # Analytics endpoints
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ pairService.ts   # Pair operations
â”‚   â”‚   â”‚   â”œâ”€â”€ positionService.ts # Position calculations
â”‚   â”‚   â”‚   â”œâ”€â”€ priceService.ts  # Price feed operations
â”‚   â”‚   â”‚   â””â”€â”€ analyticsService.ts # Analytics
â”‚   â”‚   â”œâ”€â”€ middleware/          # Express middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.ts          # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ rateLimit.ts     # Rate limiting
â”‚   â”‚   â”‚   â”œâ”€â”€ cors.ts          # CORS configuration
â”‚   â”‚   â”‚   â””â”€â”€ validation.ts    # Request validation
â”‚   â”‚   â”œâ”€â”€ types/               # TypeScript definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts           # API types
â”‚   â”‚   â”‚   â”œâ”€â”€ database.ts      # Database types
â”‚   â”‚   â”‚   â””â”€â”€ omnipair.ts      # Protocol types
â”‚   â”‚   â””â”€â”€ utils/               # Utilities
â”‚   â”‚       â”œâ”€â”€ logger.ts        # Logging
â”‚   â”‚       â”œâ”€â”€ cache.ts         # Caching
â”‚   â”‚       â””â”€â”€ validation.ts    # Validation helpers
â”‚   â”œâ”€â”€ tests/                   # Test files
â”‚   â”‚   â”œâ”€â”€ integration/         # Integration tests
â”‚   â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â”‚   â””â”€â”€ fixtures/           # Test data
â”‚   â””â”€â”€ README.md                # API documentation
â”‚
â”œâ”€â”€ database/                    # ğŸ—„ï¸ Database Layer
â”‚   â”œâ”€â”€ package.json             # Database dependencies
â”‚   â”œâ”€â”€ drizzle.config.ts        # Drizzle configuration
â”‚   â”œâ”€â”€ tsconfig.json            # TypeScript config
â”‚   â”œâ”€â”€ lib/                     # Library exports
â”‚   â”‚   â”œâ”€â”€ index.ts             # Main exports
â”‚   â”‚   â””â”€â”€ schema.ts            # Schema definitions
â”‚   â”œâ”€â”€ src/                     # Source code
â”‚   â”‚   â”œâ”€â”€ index.ts             # Migration runner
â”‚   â”‚   â””â”€â”€ run-sql.ts           # SQL utilities
â”‚   â”œâ”€â”€ migrations/              # Generated migrations
â”‚   â”‚   â”œâ”€â”€ 0001_initial.sql     # Initial schema
â”‚   â”‚   â””â”€â”€ meta/                # Migration metadata
â”‚   â”œâ”€â”€ sql/                     # Custom SQL scripts
â”‚   â”‚   â”œâ”€â”€ setup-timescaledb.sql # TimescaleDB setup
â”‚   â”‚   â”œâ”€â”€ indexes.sql          # Performance indexes
â”‚   â”‚   â””â”€â”€ views.sql            # Database views
â”‚   â””â”€â”€ README.md                # Database documentation
â”‚
â””â”€â”€ docs/                        # ğŸ“š Additional Documentation
    â”œâ”€â”€ architecture.md          # Architecture deep-dive
    â”œâ”€â”€ deployment.md            # Deployment guides
    â””â”€â”€ troubleshooting.md       # Common issues
```

## ğŸ› ï¸ Development Setup

### Prerequisites

- **Rust 1.82+**: [rustup.rs](https://rustup.rs/)
- **Bun 1.0+**: [bun.sh](https://bun.sh/)
- **PostgreSQL 14+**: With TimescaleDB extension
- **Git**: Version control
- **IDE**: VS Code with Rust Analyzer and TypeScript extensions

### Initial Setup

```bash
# Clone repository
git clone <repository-url>
cd omnipair-indexer

# Install dependencies
bun install

# Setup database
createdb omnipair_indexer
psql omnipair_indexer -c "CREATE EXTENSION IF NOT EXISTS timescaledb;"

# Run migrations
cd database && bun run migrate
psql omnipair_indexer -f sql/setup-timescaledb.sql
cd ..

# Configure environment
cp env.template .env
# Edit .env with your settings
```

### Development Workflow

#### 1. Indexer Development (Rust)

```bash
# Build and run
cargo build -p omnipair-carbon-indexer
cargo run -p omnipair-carbon-indexer

# Development with auto-reload
cargo install cargo-watch
cargo watch -x "run -p omnipair-carbon-indexer"

# Testing
cargo test
cargo test --package omnipair-carbon-indexer

# Code quality
cargo fmt
cargo clippy
cargo clippy -- -D warnings
```

#### 2. API Development (TypeScript)

```bash
# Development server
cd api
bun run dev

# Build and run
bun run build
bun run start

# Testing
bun test
bun test --watch

# Code quality
bun run lint
bun run type-check
bun run format
```

#### 3. Database Development

```bash
# Create migration
cd database
bun run migrate:create

# Apply migrations
bun run migrate

# Run custom SQL
bun run sql path/to/script.sql

# Reset database (development only)
dropdb omnipair_indexer && createdb omnipair_indexer
psql omnipair_indexer -c "CREATE EXTENSION IF NOT EXISTS timescaledb;"
bun run migrate
```

## ğŸ”§ Adding New Features

### Adding New Event Types

#### 1. Update Rust Decoder

```rust
// indexer/decoders/omnipair_decoder/src/instructions/mod.rs
pub mod new_event;

// indexer/decoders/omnipair_decoder/src/instructions/new_event.rs
use carbon_core::deserialize::CarbonDeserialize;

#[derive(Debug, Clone, CarbonDeserialize)]
pub struct NewEvent {
    pub user: Pubkey,
    pub amount: u64,
    pub timestamp: i64,
}
```

#### 2. Add Event Processing

```rust
// indexer/src/main.rs
pub struct NewEventProcessor;

#[async_trait]
impl Processor for NewEventProcessor {
    type InputType = InstructionProcessorInputType<NewEvent>;
    
    async fn process(&mut self, update: Self::InputType, metrics: Arc<MetricsCollection>) -> CarbonResult<()> {
        let (metadata, instruction, _raw_instruction) = update;
        
        // Process the new event
        log::info!("Processing new event: {:?}", instruction);
        
        // TODO: Add database write logic when database integration is ready
        
        Ok(())
    }
}
```

#### 3. Update Database Schema

```typescript
// database/lib/schema.ts
export const newEvents = pgTable('new_events', {
  id: uuid('id').primaryKey().default(sql`gen_random_uuid()`),
  txSignature: varchar('tx_signature', { length: 88 }).notNull(),
  userAddress: varchar('user_address', { length: 44 }).notNull(),
  amount: bigint('amount', { mode: 'bigint' }).notNull(),
  timestamp: timestamp('timestamp', { withTimezone: true }).notNull(),
  createdAt: timestamp('created_at', { withTimezone: true }).notNull().defaultNow(),
});
```

#### 4. Add API Endpoint

```typescript
// api/src/routes/newEvents.ts
import { Request, Response } from 'express';
import { db } from '../database';
import { newEvents } from '../database/schema';

export const getNewEvents = async (req: Request, res: Response) => {
  try {
    const events = await db.select().from(newEvents).limit(100);
    
    res.json({
      success: true,
      data: events,
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
};
```

### Adding New API Endpoints

#### 1. Create Route Handler

```typescript
// api/src/routes/newEndpoint.ts
import { Request, Response } from 'express';
import { z } from 'zod';

const QuerySchema = z.object({
  limit: z.coerce.number().min(1).max(1000).default(100),
  offset: z.coerce.number().min(0).default(0),
});

export const newEndpointHandler = async (req: Request, res: Response) => {
  try {
    const query = QuerySchema.parse(req.query);
    
    // Business logic here
    const result = await processNewEndpoint(query);
    
    res.json({
      success: true,
      data: result,
      pagination: {
        limit: query.limit,
        offset: query.offset,
      },
    });
  } catch (error) {
    if (error instanceof z.ZodError) {
      return res.status(400).json({
        success: false,
        error: 'Validation error',
        details: error.errors,
      });
    }
    
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
};
```

#### 2. Register Route

```typescript
// api/src/index.ts
import { newEndpointHandler } from './routes/newEndpoint';

app.get('/api/new-endpoint', newEndpointHandler);
```

#### 3. Add Tests

```typescript
// api/tests/integration/newEndpoint.test.ts
import { describe, it, expect, beforeAll, afterAll } from 'bun:test';
import request from 'supertest';
import { app } from '../../src/index';

describe('New Endpoint', () => {
  it('should return data successfully', async () => {
    const response = await request(app)
      .get('/api/new-endpoint')
      .query({ limit: 10 })
      .expect(200);
      
    expect(response.body.success).toBe(true);
    expect(response.body.data).toBeDefined();
  });
});
```

### Adding Database Migrations

#### 1. Schema Changes

```typescript
// database/lib/schema.ts
export const newTable = pgTable('new_table', {
  id: uuid('id').primaryKey().default(sql`gen_random_uuid()`),
  name: varchar('name', { length: 255 }).notNull(),
  value: decimal('value', { precision: 20, scale: 6 }),
  createdAt: timestamp('created_at', { withTimezone: true }).notNull().defaultNow(),
});
```

#### 2. Generate Migration

```bash
cd database
bun run migrate:create
```

#### 3. Custom Migration (if needed)

```sql
-- database/migrations/0003_custom_changes.sql
-- Add custom indexes
CREATE INDEX CONCURRENTLY idx_new_table_name ON new_table (name);

-- Add TimescaleDB hypertable
SELECT create_hypertable('time_series_table', 'timestamp');

-- Add compression policy
SELECT add_compression_policy('time_series_table', INTERVAL '7 days');
```

## ğŸ§ª Testing

### Rust Testing

```bash
# Run all tests
cargo test

# Run specific package tests
cargo test -p omnipair-carbon-indexer

# Run with output
cargo test -- --nocapture

# Run specific test
cargo test test_account_processing

# Integration tests
cargo test --test integration_tests
```

### TypeScript Testing

```bash
# Run all tests
cd api && bun test

# Run with watch mode
bun test --watch

# Run specific test file
bun test src/routes/pairs.test.ts

# Run integration tests
bun test tests/integration/

# Coverage report
bun test --coverage
```

### Database Testing

```bash
# Test migrations
cd database
DATABASE_URL=postgresql://test_user:test_pass@localhost/test_db bun run migrate

# Test schema generation
bun run migrate:create

# Validate schema
bun run validate-schema
```

## ğŸ“Š Performance Optimization

### Rust Indexer Optimization

#### 1. Memory Management

```rust
// Use Arc for shared data
use std::sync::Arc;

// Implement efficient batching
const BATCH_SIZE: usize = 1000;
let mut batch = Vec::with_capacity(BATCH_SIZE);

// Use channels for async communication
let (sender, receiver) = tokio::sync::mpsc::channel(1000);
```

#### 2. Database Connection Pooling

```rust
// Future implementation for database integration
use sqlx::PgPool;

let pool = PgPool::connect_with(
    PgConnectOptions::new()
        .max_connections(10)
        .min_connections(2)
        .idle_timeout(Duration::from_secs(30))
).await?;
```

### API Server Optimization

#### 1. Database Query Optimization

```typescript
// Use indexes effectively
const results = await db
  .select()
  .from(transactionDetails)
  .where(
    and(
      eq(transactionDetails.pairAddress, pairAddress),
      gte(transactionDetails.time, startTime)
    )
  )
  .orderBy(desc(transactionDetails.time))
  .limit(100);

// Use prepared statements for repeated queries
const getRecentTransactions = db
  .select()
  .from(transactionDetails)
  .where(eq(transactionDetails.pairAddress, $pairAddress))
  .orderBy(desc(transactionDetails.time))
  .limit($limit)
  .prepare();
```

#### 2. Caching Strategy

```typescript
// Redis caching (planned)
import Redis from 'ioredis';

const redis = new Redis(process.env.REDIS_URL);

// Cache frequently accessed data
const cacheKey = `pairs:${pairAddress}`;
const cached = await redis.get(cacheKey);

if (cached) {
  return JSON.parse(cached);
}

const data = await fetchPairData(pairAddress);
await redis.setex(cacheKey, 300, JSON.stringify(data)); // 5 min cache
```

### Database Optimization

#### 1. TimescaleDB Configuration

```sql
-- Optimize chunk intervals
SELECT set_chunk_time_interval('transaction_details', INTERVAL '1 day');

-- Enable compression
ALTER TABLE transaction_details SET (
  timescaledb.compress,
  timescaledb.compress_segmentby = 'pair_address',
  timescaledb.compress_orderby = 'time DESC'
);

-- Add compression policy
SELECT add_compression_policy('transaction_details', INTERVAL '7 days');
```

#### 2. Index Strategy

```sql
-- Composite indexes for common queries
CREATE INDEX CONCURRENTLY idx_transactions_pair_time_type 
ON transaction_details (pair_address, time DESC, transaction_type);

-- Partial indexes for filtered queries
CREATE INDEX CONCURRENTLY idx_transactions_swaps 
ON transaction_details (time DESC) 
WHERE transaction_type = 'swap';

-- BRIN indexes for time-series data
CREATE INDEX CONCURRENTLY idx_transactions_time_brin 
ON transaction_details USING BRIN (time);
```

## ğŸš€ Deployment

### Railway Deployment

#### 1. Service Configuration

Each service has its own `railway.toml`:

```toml
# indexer/railway.toml
[build]
builder = "nixpacks"
buildCommand = "cargo build --release"

[deploy]
startCommand = "./target/release/omnipair-carbon-indexer"
restartPolicyType = "always"
numReplicas = 1

# api/railway.toml
[build]
builder = "nixpacks"
buildCommand = "bun install"

[deploy]
startCommand = "bun run start"
restartPolicyType = "always"
numReplicas = 1
```

#### 2. Environment Variables

```bash
# Shared across services
DATABASE_URL=${{Postgres.DATABASE_URL}}
SOLANA_RPC_URL=https://your-premium-rpc.com
SOLANA_WS_URL=wss://your-premium-ws.com

# Service-specific variables
RUST_LOG=info                    # Indexer
NODE_ENV=production              # API
PORT=3000                        # API
```

### Docker Deployment (Planned)

```dockerfile
# Dockerfile.indexer
FROM rust:1.82-slim as builder
WORKDIR /app
COPY . .
RUN cargo build --release -p omnipair-carbon-indexer

FROM debian:bookworm-slim
COPY --from=builder /app/target/release/omnipair-carbon-indexer /usr/local/bin/
CMD ["omnipair-carbon-indexer"]

# Dockerfile.api
FROM oven/bun:1-slim
WORKDIR /app
COPY api/package.json api/bun.lockb ./
RUN bun install --frozen-lockfile
COPY api/ .
EXPOSE 3000
CMD ["bun", "run", "start"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: timescale/timescaledb:latest-pg14
    environment:
      POSTGRES_DB: omnipair_indexer
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  indexer:
    build:
      context: .
      dockerfile: Dockerfile.indexer
    environment:
      DATABASE_URL: postgresql://postgres:password@postgres:5432/omnipair_indexer
      RPC_URL: https://api.mainnet-beta.solana.com
      RPC_WS_URL: wss://api.mainnet-beta.solana.com
      RUST_LOG: info
    depends_on:
      - postgres

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    environment:
      DATABASE_URL: postgresql://postgres:password@postgres:5432/omnipair_indexer
      NODE_ENV: production
      PORT: 3000
    ports:
      - "3000:3000"
    depends_on:
      - postgres

volumes:
  postgres_data:
```

## ğŸ” Debugging and Monitoring

### Logging Configuration

#### Rust Indexer

```bash
# Different log levels
RUST_LOG=debug cargo run -p omnipair-carbon-indexer
RUST_LOG=carbon_core=debug,omnipair_carbon_indexer=info cargo run

# Structured JSON logging
RUST_LOG=info cargo run 2>&1 | jq '.'
```

#### TypeScript API

```typescript
// api/src/utils/logger.ts
import pino from 'pino';

export const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard',
    },
  },
});

// Usage
logger.info({ pairAddress, volume }, 'Processing pair data');
logger.error({ error: error.message, stack: error.stack }, 'API error');
```

### Health Monitoring

```typescript
// api/src/routes/health.ts
export const healthCheck = async (req: Request, res: Response) => {
  const health = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    services: {
      database: await checkDatabaseHealth(),
      indexer: await checkIndexerHealth(),
    },
    metrics: {
      memoryUsage: process.memoryUsage(),
      cpuUsage: process.cpuUsage(),
    },
  };
  
  res.json(health);
};
```

### Performance Monitoring

```sql
-- Database performance queries
SELECT 
  schemaname,
  tablename,
  n_tup_ins,
  n_tup_upd,
  n_tup_del,
  n_live_tup,
  n_dead_tup
FROM pg_stat_user_tables
ORDER BY n_tup_ins DESC;

-- Index usage statistics
SELECT 
  indexrelname,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;

-- TimescaleDB chunk information
SELECT 
  chunk_schema,
  chunk_name,
  range_start,
  range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'transaction_details'
ORDER BY range_start DESC;
```

## ğŸ¤ Contributing Guidelines

### Code Style

#### Rust
- Use `cargo fmt` for formatting
- Run `cargo clippy` and fix all warnings
- Follow Rust naming conventions
- Add documentation comments for public APIs
- Write tests for new functionality

#### TypeScript
- Use Prettier for formatting
- Follow ESLint rules
- Use strict TypeScript configuration
- Add JSDoc comments for complex functions
- Write unit and integration tests

### Pull Request Process

1. **Fork and Branch**: Create a feature branch from `main`
2. **Development**: Make changes following style guidelines
3. **Testing**: Add tests and ensure all tests pass
4. **Documentation**: Update relevant documentation
5. **Review**: Submit PR with clear description
6. **Integration**: Squash merge after approval

### Commit Messages

Use conventional commits format:

```
feat(indexer): add new event type processing
fix(api): resolve pagination issue in pairs endpoint
docs(database): update schema documentation
refactor(api): improve error handling middleware
test(indexer): add integration tests for account processing
```

---

**Note**: This development guide is a living document. Please keep it updated as the project evolves and new patterns emerge.